{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# imports\nimport os\nimport gc\nimport csv\nimport glob\nimport torch\nimport multiprocessing\n\nimport numpy as np\nimport pandas as pd\nimport torch.nn as nn\nimport matplotlib.pyplot as plt\n\nimport torch.optim as optim\nimport torch.nn.functional as F\nimport torch.backends.cudnn as cudnn\nfrom torch.autograd import Variable\n\nimport torchvision\nimport torchvision.transforms as transforms","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-28T10:06:04.870913Z","iopub.execute_input":"2025-07-28T10:06:04.871157Z","iopub.status.idle":"2025-07-28T10:06:14.773445Z","shell.execute_reply.started":"2025-07-28T10:06:04.871133Z","shell.execute_reply":"2025-07-28T10:06:14.772893Z"}},"outputs":[],"execution_count":1},{"cell_type":"markdown","source":"# Set random seed","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"# @title Set random seed\n\n# @markdown Executing `set_seed(seed=seed)` you are setting the seed\n\n# for DL its critical to set the random seed so we can have a\n# baseline to compare results to expected results.\n# Read more here: https://pytorch.org/docs/stable/notes/randomness.html\n\n# Call `set_seed` function in the exercises to ensure reproducibility.\nimport random\nimport torch\n\ndef set_seed(seed=None, seed_torch=True):\n  if seed is None:\n    seed = np.random.choice(2 ** 32)\n  random.seed(seed)\n  np.random.seed(seed)\n  if seed_torch:\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.benchmark = False\n    torch.backends.cudnn.deterministic = True\n\n  print(f'Random seed {seed} has been set.')\n\n# In case that `DataLoader` is used\ndef seed_worker(worker_id):\n  worker_seed = torch.initial_seed() % 2**32\n  np.random.seed(worker_seed)\n  random.seed(worker_seed)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-28T10:06:19.587928Z","iopub.execute_input":"2025-07-28T10:06:19.588485Z","iopub.status.idle":"2025-07-28T10:06:19.593949Z","shell.execute_reply.started":"2025-07-28T10:06:19.588460Z","shell.execute_reply":"2025-07-28T10:06:19.593273Z"}},"outputs":[],"execution_count":2},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"# Set device (GPU or CPU)","metadata":{}},{"cell_type":"code","source":"# @title Set device (GPU or CPU)\n\n# inform the user if the notebook uses GPU or CPU.\n\ndef set_device():\n  device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n  if device != \"cuda\":\n    print(\"WARNING: For this notebook to perform best, \"\n        \"if possible, in the menu under `Runtime` -> \"\n        \"`Change runtime type.`  select `GPU` \")\n  else:\n    print(\"GPU is enabled in this notebook.\")\n\n  return device","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-28T10:06:23.586200Z","iopub.execute_input":"2025-07-28T10:06:23.586471Z","iopub.status.idle":"2025-07-28T10:06:23.591063Z","shell.execute_reply.started":"2025-07-28T10:06:23.586450Z","shell.execute_reply":"2025-07-28T10:06:23.590282Z"}},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":"# Random Seeds","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"set_seed(seed=2021)\ndevice = set_device()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-28T10:06:26.077392Z","iopub.execute_input":"2025-07-28T10:06:26.077710Z","iopub.status.idle":"2025-07-28T10:06:26.182889Z","shell.execute_reply.started":"2025-07-28T10:06:26.077685Z","shell.execute_reply":"2025-07-28T10:06:26.182036Z"}},"outputs":[{"name":"stdout","text":"Random seed 2021 has been set.\nGPU is enabled in this notebook.\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"# hyper-parameters\nuse_cuda = torch.cuda.is_available()\nbest_acc = 0  # best test accuracy\nstart_epoch = 0  # start from epoch 0 or last checkpoint epoch\nbatch_size = 128\nmax_epochs = 120  \nbase_learning_rate = 0.1\ntorchvision_transforms = True  # True/False if you want use torchvision augmentations","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-28T10:06:28.736849Z","iopub.execute_input":"2025-07-28T10:06:28.737192Z","iopub.status.idle":"2025-07-28T10:06:28.741673Z","shell.execute_reply.started":"2025-07-28T10:06:28.737164Z","shell.execute_reply":"2025-07-28T10:06:28.740900Z"}},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":"# Source dataset for pretraining","metadata":{}},{"cell_type":"code","source":"# @markdown Download and prepare Data\nprint('==> Preparing data..')\ndef percentageSplit(full_dataset, percent = 0.0):\n  set1_size = int(percent * len(full_dataset))\n  set2_size = len(full_dataset) - set1_size\n  final_dataset, _ = torch.utils.data.random_split(full_dataset, [set1_size, set2_size])\n  return final_dataset\n\n\n# CIFAR100 normalizing\nmean = [0.5071, 0.4866, 0.4409]\nstd = [0.2673, 0.2564, 0.2762]\n\n# CIFAR10 normalizing\n# mean = (0.4914, 0.4822, 0.4465)\n# std = (0.2023, 0.1994, 0.2010)\n\n# torchvision transforms\ntransform_train = transforms.Compose([])\nif torchvision_transforms:\n  transform_train.transforms.append(transforms.RandomCrop(32, padding=4))\n  transform_train.transforms.append(transforms.RandomHorizontalFlip())\n\ntransform_train.transforms.append(transforms.ToTensor())\ntransform_train.transforms.append(transforms.Normalize(mean, std))\n\ntransform_test = transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Normalize(mean, std),\n])\n\ntrainset = torchvision.datasets.CIFAR100(\n  root='./CIFAR100', train=True, download=True, transform=transform_train)\n\ntestset = torchvision.datasets.CIFAR100(\n  root='./CIFAR100', train=False, download=True, transform=transform_test)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-28T10:06:31.136857Z","iopub.execute_input":"2025-07-28T10:06:31.137131Z","iopub.status.idle":"2025-07-28T10:06:38.752271Z","shell.execute_reply.started":"2025-07-28T10:06:31.137110Z","shell.execute_reply":"2025-07-28T10:06:38.751655Z"}},"outputs":[{"name":"stdout","text":"==> Preparing data..\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 169M/169M [00:03<00:00, 45.9MB/s] \n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"print(f\"Object type: {type(trainset)}\")\nprint(f\"Training data shape: {trainset.data.shape}\")\nprint(f\"Test data shape: {testset.data.shape}\")\nprint(f\"Number of classes: {np.unique(trainset.targets).shape[0]}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-28T10:07:31.868840Z","iopub.execute_input":"2025-07-28T10:07:31.869351Z","iopub.status.idle":"2025-07-28T10:07:31.880612Z","shell.execute_reply.started":"2025-07-28T10:07:31.869326Z","shell.execute_reply":"2025-07-28T10:07:31.879731Z"}},"outputs":[{"name":"stdout","text":"Object type: <class 'torchvision.datasets.cifar.CIFAR100'>\nTraining data shape: (50000, 32, 32, 3)\nTest data shape: (10000, 32, 32, 3)\nNumber of classes: 100\n","output_type":"stream"}],"execution_count":7},{"cell_type":"markdown","source":"# Dataloaders","metadata":{}},{"cell_type":"code","source":"##@title Dataloader\nnum_workers = multiprocessing.cpu_count()\n\nprint(f'----> number of workers: {num_workers}')\n\ntrainloader = torch.utils.data.DataLoader(\n    trainset, batch_size=batch_size, shuffle=True, num_workers=num_workers)\ntestloader = torch.utils.data.DataLoader(\n    testset, batch_size=batch_size, shuffle=False, num_workers=num_workers)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-28T10:07:34.622299Z","iopub.execute_input":"2025-07-28T10:07:34.622835Z","iopub.status.idle":"2025-07-28T10:07:34.627446Z","shell.execute_reply.started":"2025-07-28T10:07:34.622815Z","shell.execute_reply":"2025-07-28T10:07:34.626707Z"}},"outputs":[{"name":"stdout","text":"----> number of workers: 4\n","output_type":"stream"}],"execution_count":8},{"cell_type":"markdown","source":"# Resnet","metadata":{}},{"cell_type":"code","source":"# @title ResNet model in PyTorch\n\nclass BasicBlock(nn.Module):\n  \"\"\"ResNet in PyTorch.\n      Reference:\n      [1] Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun\n        Deep Residual Learning for Image Recognition. arXiv:1512.03385\n  \"\"\"\n\n  expansion = 1\n\n  def __init__(self, in_planes, planes, stride=1):\n    super(BasicBlock, self).__init__()\n    self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n    self.bn1 = nn.BatchNorm2d(planes)\n    self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n    self.bn2 = nn.BatchNorm2d(planes)\n\n    self.shortcut = nn.Sequential()\n    if stride != 1 or in_planes != self.expansion*planes:\n        self.shortcut = nn.Sequential(\n            nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False),\n            nn.BatchNorm2d(self.expansion*planes)\n        )\n\n  def forward(self, x):\n    out = F.relu(self.bn1(self.conv1(x)))\n    out = self.bn2(self.conv2(out))\n    out += self.shortcut(x)\n    out = F.relu(out)\n    return out\n\n\nclass Bottleneck(nn.Module):\n  expansion = 4\n\n  def __init__(self, in_planes, planes, stride=1):\n    super(Bottleneck, self).__init__()\n    self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)\n    self.bn1 = nn.BatchNorm2d(planes)\n    self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n    self.bn2 = nn.BatchNorm2d(planes)\n    self.conv3 = nn.Conv2d(planes, self.expansion*planes, kernel_size=1, bias=False)\n    self.bn3 = nn.BatchNorm2d(self.expansion*planes)\n\n    self.shortcut = nn.Sequential()\n    if stride != 1 or in_planes != self.expansion*planes:\n        self.shortcut = nn.Sequential(\n            nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False),\n            nn.BatchNorm2d(self.expansion*planes)\n        )\n\n  def forward(self, x):\n    out = F.relu(self.bn1(self.conv1(x)))\n    out = F.relu(self.bn2(self.conv2(out)))\n    out = self.bn3(self.conv3(out))\n    out += self.shortcut(x)\n    out = F.relu(out)\n    return out\n\n\nclass ResNet(nn.Module):\n  def __init__(self, block, num_blocks, num_classes=100):\n    super(ResNet, self).__init__()\n    self.in_planes = 64\n\n    self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n    self.bn1 = nn.BatchNorm2d(64)\n    self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n    self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n    self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n    self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n    self.linear = nn.Linear(512*block.expansion, num_classes)\n\n  def _make_layer(self, block, planes, num_blocks, stride):\n    strides = [stride] + [1]*(num_blocks-1)\n    layers = []\n    for stride in strides:\n      layers.append(block(self.in_planes, planes, stride))\n      self.in_planes = planes * block.expansion\n    return nn.Sequential(*layers)\n\n  def forward(self, x):\n    out = F.relu(self.bn1(self.conv1(x)))\n    out = self.layer1(out)\n    out = self.layer2(out)\n    out = self.layer3(out)\n    out = self.layer4(out)\n    out = F.avg_pool2d(out, 4)\n    out = out.view(out.size(0), -1)\n    out = self.linear(out)\n    return out\n\n\ndef ResNet18():\n  return ResNet(BasicBlock, [2, 2, 2, 2])\n\n\ndef ResNet34():\n  return ResNet(BasicBlock, [3, 4, 6, 3])\n\n\ndef ResNet50():\n  return ResNet(Bottleneck, [3, 4, 6, 3])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-28T10:07:36.758970Z","iopub.execute_input":"2025-07-28T10:07:36.759276Z","iopub.status.idle":"2025-07-28T10:07:36.775623Z","shell.execute_reply.started":"2025-07-28T10:07:36.759253Z","shell.execute_reply":"2025-07-28T10:07:36.774896Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"# Load the Model\nnet = ResNet50()\nprint('-----> verify if model is run on random data')\ny = net(Variable(torch.randn(1,3,32,32)))\nprint('model loaded')\n\nresult_folder = './results/'\nif not os.path.exists(result_folder):\n    os.makedirs(result_folder)\n\nlogname = result_folder + net.__class__.__name__ + '_pretrain' + '.csv'\n\nif use_cuda:\n  net.cuda()\n  net = torch.nn.DataParallel(net)\n  print('Using', torch.cuda.device_count(), 'GPUs.')\n  cudnn.benchmark = True\n  print('Using CUDA..')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-28T10:07:40.036252Z","iopub.execute_input":"2025-07-28T10:07:40.036945Z","iopub.status.idle":"2025-07-28T10:07:40.690025Z","shell.execute_reply.started":"2025-07-28T10:07:40.036919Z","shell.execute_reply":"2025-07-28T10:07:40.689188Z"}},"outputs":[{"name":"stdout","text":"-----> verify if model is run on random data\nmodel loaded\nUsing 2 GPUs.\nUsing CUDA..\n","output_type":"stream"}],"execution_count":10},{"cell_type":"markdown","source":"# Loss function & optimizer","metadata":{}},{"cell_type":"code","source":"# Optimizer and criterion\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.SGD(net.parameters(), lr=base_learning_rate, momentum=0.9, weight_decay=1e-4)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-28T10:07:43.395969Z","iopub.execute_input":"2025-07-28T10:07:43.396621Z","iopub.status.idle":"2025-07-28T10:07:43.401089Z","shell.execute_reply.started":"2025-07-28T10:07:43.396598Z","shell.execute_reply":"2025-07-28T10:07:43.400405Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"# Training & Test functions\n\ndef train(net, epoch, use_cuda=True):\n  print('\\nEpoch: %d' % epoch)\n  net.train()\n  train_loss = 0\n  correct = 0\n  total = 0\n  for batch_idx, (inputs, targets) in enumerate(trainloader):\n    if use_cuda:\n      inputs, targets = inputs.cuda(), targets.cuda()\n\n    optimizer.zero_grad()\n    inputs, targets = Variable(inputs), Variable(targets)\n    outputs = net(inputs)\n    loss = criterion(outputs, targets)\n    loss.backward()\n    optimizer.step()\n\n    train_loss += loss.item()\n    _, predicted = torch.max(outputs.data, 1)\n    total += targets.size(0)\n    correct += predicted.eq(targets.data).cpu().sum()\n\n    if batch_idx % 500 == 0:\n      print(batch_idx, len(trainloader), 'Loss: %.3f | Acc: %.3f%% (%d/%d)'\n          % (train_loss/(batch_idx+1), 100.*correct/total, correct, total))\n  return (train_loss/batch_idx, 100.*correct/total)\n\n\ndef test(net, epoch, outModelName, use_cuda=True):\n  global best_acc\n  net.eval()\n  test_loss, correct, total = 0, 0, 0\n  with torch.no_grad():\n    for batch_idx, (inputs, targets) in enumerate(testloader):\n      if use_cuda:\n        inputs, targets = inputs.cuda(), targets.cuda()\n\n      outputs = net(inputs)\n      loss = criterion(outputs, targets)\n\n      test_loss += loss.item()\n      _, predicted = torch.max(outputs.data, 1)\n      total += targets.size(0)\n      correct += predicted.eq(targets.data).cpu().sum()\n\n      if batch_idx % 200 == 0:\n        print(batch_idx, len(testloader), 'Loss: %.3f | Acc: %.3f%% (%d/%d)'\n            % (test_loss/(batch_idx+1), 100.*correct/total, correct, total))\n\n  # Save checkpoint.\n  acc = 100.*correct/total\n  if acc > best_acc:\n    best_acc = acc\n    checkpoint(net, acc, epoch, outModelName)\n  return (test_loss/batch_idx, 100.*correct/total)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-28T10:07:48.615788Z","iopub.execute_input":"2025-07-28T10:07:48.616230Z","iopub.status.idle":"2025-07-28T10:07:48.624884Z","shell.execute_reply.started":"2025-07-28T10:07:48.616209Z","shell.execute_reply":"2025-07-28T10:07:48.624012Z"}},"outputs":[],"execution_count":12},{"cell_type":"markdown","source":"# Checkpoint and adjusting learning rate","metadata":{}},{"cell_type":"code","source":"# checkpoint & adjust_learning_rate\ndef checkpoint(model, acc, epoch, outModelName):\n  # Save checkpoint.\n  print('Saving..')\n  state = {\n      'state_dict': model.state_dict(),\n      'acc': acc,\n      'epoch': epoch,\n      'rng_state': torch.get_rng_state()\n  }\n  if not os.path.isdir('checkpoint'):\n      os.mkdir('checkpoint')\n  torch.save(state, f'./checkpoint/{outModelName}.t7')\n\ndef adjust_learning_rate(optimizer, epoch):\n  \"\"\"decrease the learning rate at 100 and 150 epoch\"\"\"\n  lr = base_learning_rate\n  if epoch <= 9 and lr > 0.1:\n    # warm-up training for large minibatch\n    lr = 0.1 + (base_learning_rate - 0.1) * epoch / 10.\n  if epoch >= 100:\n    lr /= 10\n  if epoch >= 150:\n    lr /= 10\n  for param_group in optimizer.param_groups:\n    param_group['lr'] = lr","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-28T10:07:52.173257Z","iopub.execute_input":"2025-07-28T10:07:52.173528Z","iopub.status.idle":"2025-07-28T10:07:52.179166Z","shell.execute_reply.started":"2025-07-28T10:07:52.173498Z","shell.execute_reply":"2025-07-28T10:07:52.178476Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"# Start training\noutModelName = 'pretrain'\nif not os.path.exists(logname):\n  with open(logname, 'w') as logfile:\n      logwriter = csv.writer(logfile, delimiter=',')\n      logwriter.writerow(['epoch', 'train loss', 'train acc', 'test loss', 'test acc'])\n\nfor epoch in range(start_epoch, max_epochs):\n  adjust_learning_rate(optimizer, epoch)\n  train_loss, train_acc = train(net, epoch, use_cuda=use_cuda)\n  test_loss, test_acc = test(net, epoch, outModelName, use_cuda=use_cuda)\n  with open(logname, 'a') as logfile:\n    logwriter = csv.writer(logfile, delimiter=',')\n    logwriter.writerow([epoch, train_loss, train_acc.item(), test_loss, test_acc.item()])\n  print(f'Epoch: {epoch} | train acc: {train_acc} | test acc: {test_acc}')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# delete the backbone network\ndelete = True\nif delete:\n   del net\n   del trainset\n   del testset\n   del trainloader\n   del testloader\n   gc.collect()","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}